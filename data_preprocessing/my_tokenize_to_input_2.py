import numpy as np
import re
import os


# æ­£åˆ™è¡¨è¾¾å¼
p1 = r'^[\.!@#\$%\\\^&\*\)\(\+=\{\}\[\]\/\",\'\â€œ\â€\â€™<>~\Â·`\?:;|\-\s]{2,}$'
p2 = r'[^a-zA-Z0-9\.!@#\$%\\\^&\*\)\(\+=\{\}\[\]\/\",\'\â€œ\â€\â€™<>~\Â·`\?:;|\-\s]+'
p3 = r'(\w+?)/(\w+)'  # \w=[A-Za-z0-9_]
p4 = r'(.+)@(.+)'
p5 = r'([A-Z]*[a-z]+)\.([A-Z]*[a-z]+)'  # éå¤§å†™å­—æ¯
p6 = r'(\w+)\?(\w+)'
p7 = r'[A-Z]+'
p8 = r'[ğŸ˜„ğŸš«ğŸš¨ğŸ™‹ğŸ™„ğŸ™ƒğŸ˜­ğŸ˜©ğŸ˜¨ğŸ˜¦ğŸ˜¥ğŸ˜¤ğŸ˜ ğŸ˜•ğŸ˜”ğŸ˜„ğŸ‘ºğŸ‘ŒğŸ¸ğŸ¸ğŸâŒâ™¡â˜•ï¸â˜•â–ºâ€¦Ğ½ĞµğŸ˜±ğŸ˜ªğŸ‘ğŸ‘ğŸ‘‡â¤ï¸ğŸ˜´ğŸ˜‚ğŸ™ğŸ’”ğŸ’œğŸ˜’]+'
p9 = r'(.*)urlurlurl(.+)'
p10 = r'(.+)urlurlurl(.*)'
p11 = r'[\.!@#\$%\\\^&\*\)\(\+=\{\}\[\]\/\",\'\â€œ\â€\â€™<>~\Â·`\?:;|\-\s]+(\d+)'
p12 = r'[\s\n\r\t]+'



def clean_tokenized_text():
    cleaned_tokenized_branch_tweet_id = {}
    cleaned_tokenized_branch_tweet_id['train']=[]
    cleaned_tokenized_branch_tweet_id['dev']=[]
    cleaned_tokenized_branch_tweet_id['test'] = []

    whichset = ['train', 'dev','test']  # 19rumor

    for sset in whichset:
        tokenized_branch_tweet_id = np.load('data/taskA_newformdata/' + sset + '/tokenized_branch_id_A_B_label_stanford.npy')
        for j, branch in enumerate(tokenized_branch_tweet_id):
            branch_temp = []
            for i, tweet in enumerate(branch):
                # for i,x in enumerate(a): --æ˜¯åŠ¨æ€çš„ï¼Œaçš„é•¿åº¦åŠ¨æ€å˜åŒ–ï¼Œå°±éå†åˆ°å˜åŒ–åçš„æœ€åä¸€ä¸ªã€‚
                # ä½†iä¸€ç›´åœ¨å½“å‰åŸºç¡€ä¸Š+1ï¼Œæ‰€ä»¥è‡³å°‘åœ¨i+1çš„ä½ç½®æ’å…¥ï¼Œæ¥ä¸‹æ¥æ‰èƒ½éå†åˆ°ã€‚
                # åœ¨kä½ç½®æ’å…¥ï¼Œåˆšå¥½å°±æ˜¯å½“å‰éå†çš„å†…å®¹(éœ€ä¸æ–­æ›´æ–°word)ï¼Œæ–°æ’å…¥çš„éƒ¨åˆ†(k+1,k+2)ä¼šåœ¨æ¥ä¸‹æ¥éå†åˆ°ã€‚
                for k,word in enumerate(tweet['text']):
                    # stanford corenlp result post-processing
                    # å»ç©º
                    if not tweet['text'][k] or re.match(p12,tweet['text'][k]):  # è¿™å›åŒ¹é…åˆ°4ä¸ªï¼Œçœ‹è¯è¡¨é‡Œè¿˜ä¼šä¸ä¼šå‡ºç°ç©º
                        tweet['text'].pop(k)
                        if k >= len(tweet['text']):
                            break
                    # å»é™¤è¡¨æƒ…ç¬¦å·å’Œä¸å¸¸è§æ ‡ç‚¹
                    # åªæœ‰popæ²¡æœ‰insertå°±è‡ªåŠ¨è¿›å…¥ä¸‹ä¸€ä¸ªè¯äº†ï¼Œå…¶ä»–ç­›é€‰æ¡ä»¶éœ€è¦åœ¨è¿™ä¹‹å
                    if re.match(p2, tweet['text'][k]):  # å·²ç»ç­›æ‰535ä¸ªäº†ï¼ŒçŸ¥è¶³å§= =
                        tweet['text'].pop(k)
                        if k >= len(tweet['text']):  # åªpopä¸insertï¼Œéœ€è¦åˆ¤æ–­æ˜¯å¦popä¹‹åæ²¡æœ‰ä¸‹ä¸€ä¸ªè¯äº†ï¼Œåº”å½“é€€å‡ºæ­¤æ¬¡å¾ªç¯
                            break
                    if re.match(p8, tweet['text'][k]) or tweet['text'][k] == '':  # ä¸€äº›è¡¨æƒ…ç¬¦å·æ²¡å»é™¤å¹²å‡€çš„ï¼Œäººå·¥å»é™¤ï¼ˆåˆç­›é™¤101ä¸ªï¼‰
                        tweet['text'].pop(k)
                        if k >= len(tweet['text']):
                            break

                    # æŠŠç½‘å€è½¬æ¢æˆ 'urlurlurl'
                    if 'http' in tweet['text'][k] or 'www.' in tweet['text'][k] or '.com' in tweet['text'][k]:  # åªæœ‰ç¬¬ä¸€ä¸ªå¯ä»¥ç”¨wordï¼Œåé¢åªèƒ½ä¿®æ”¹äº†çš„å½“å‰ä½ç½®çš„è¯
                        tweet['text'][k] = 'urlurlurl'

                    # æŒ‰/åˆ‡å¼€
                    a = re.match(p3, tweet['text'][k])
                    temp_i = k
                    while a:
                        flag = 1
                        tweet['text'].pop(temp_i)
                        tweet['text'].insert(temp_i, a.group(1))
                        temp_i += 1
                        tweet['text'].insert(temp_i, '/')
                        temp_i += 1
                        latter = a.group(2)
                        a = re.match(p3, latter)
                    if temp_i > k:
                        tweet['text'].insert(temp_i, latter)

                    # æŒ‰@åˆ‡å¼€
                    b = re.match(p4,tweet['text'][k])
                    if b:
                        tweet['text'].pop(k)
                        tweet['text'].insert(k, b.group(1))
                        tweet['text'].insert(k+1, '@'+b.group(2))
                    # æŒ‰.åˆ‡å¼€
                    c = re.match(p5, tweet['text'][k])
                    temp_i = k
                    while c:
                        tweet['text'].pop(temp_i)
                        tweet['text'].insert(temp_i, c.group(1))
                        temp_i += 1
                        tweet['text'].insert(temp_i, '.')
                        temp_i += 1
                        latter = c.group(2)
                        c = re.match(p5, latter)
                    if temp_i > k:
                        tweet['text'].insert(temp_i, latter)
                    # æŒ‰?åˆ‡å¼€
                    d = re.match(p6, tweet['text'][k])
                    if d:
                        tweet['text'].pop(k)
                        tweet['text'].insert(k, d.group(1))
                        tweet['text'].insert(k + 1, '?')
                        tweet['text'].insert(k + 2, d.group(2))
                    # æŠŠ'urlurlurl'å’Œå…¶ä»–çš„å†…å®¹åˆ‡åˆ†å¼€
                    e = re.match(p9, tweet['text'][k])
                    if e:
                        tweet['text'].pop(k)
                        if e.group(1):
                            tweet['text'].insert(k, e.group(1))
                            tweet['text'].insert(k + 1, 'urlurlurl')
                            tweet['text'].insert(k + 2, e.group(2))
                        else:
                            tweet['text'].insert(k, 'urlurlurl')
                            tweet['text'].insert(k + 1, e.group(2))
                    f = re.match(p10, tweet['text'][k])
                    if f:
                        tweet['text'].pop(k)
                        tweet['text'].insert(k, f.group(1))
                        tweet['text'].insert(k + 1, 'urlurlurl')
                        if f.group(2):
                            tweet['text'].insert(k + 2, f.group(2))
                    # æŠŠå¤šä¸ªè¿èµ·æ¥çš„æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†å¼€
                    if re.match(p1, tweet['text'][k]):
                        temp_word = tweet['text'][k]
                        tweet['text'].pop(k)
                        l = len(temp_word)
                        for x in range(l):
                            tweet['text'].insert(k + x, temp_word[x])
                    # å°†æ‰€æœ‰å¸¦å¤§å†™å­—æ¯çš„è¯è½¬ä¸ºå°å†™
                    if re.findall(p7,tweet['text'][k]):
                        tweet['text'][k] = tweet['text'][k].lower()
                    # æŠŠ@userè½¬åŒ–æˆ@
                    if re.match(p1, tweet['text'][k]):
                        tweet['text'].pop(k)
                        tweet['text'].insert(k, '@')

                branch_temp.append(tweet)
            cleaned_tokenized_branch_tweet_id[sset].append(branch_temp)

        np.save(os.path.join('data/featured_data_0130/', sset, 'cleaned_tokenized_branch_A_B_label_stanford'), cleaned_tokenized_branch_tweet_id[sset])


if __name__ == "__main__":
    clean_tokenized_text()